{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7799,"status":"ok","timestamp":1700336647672,"user":{"displayName":"Ahmad Karami","userId":"07297591222472337752"},"user_tz":-210},"id":"LltLkgKHgcnQ","outputId":"f589e7c1-dee2-4efa-f11a-a5006fa2bb69"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["import torch\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","from torch.optim import Adam\n","from tqdm import tqdm\n","from torchvision.transforms import Lambda\n","# torch.nn.Module\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(device)\n"]},{"cell_type":"markdown","metadata":{"id":"jGBSVhdZgcnU"},"source":["(آ) لودکردن دیتاست"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1700336647673,"user":{"displayName":"Ahmad Karami","userId":"07297591222472337752"},"user_tz":-210},"id":"I42kZyiKgcnW"},"outputs":[],"source":["\n","class MNISTDataLoader:\n","    def __init__(self , shuffle=True):\n","        transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,)), Lambda(lambda x: torch.flatten(x))])\n","        self.train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n","        self.test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n","        self.shuffle = shuffle\n","\n","    def train_loader(self,batch_size ):\n","        return DataLoader(self.train_dataset, batch_size=batch_size, shuffle=self.shuffle)\n","\n","    def test_loader(self,batch_size):\n","        return DataLoader(self.test_dataset, batch_size=batch_size, shuffle=False)\n","\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1700336647676,"user":{"displayName":"Ahmad Karami","userId":"07297591222472337752"},"user_tz":-210},"id":"c3Y1oNEQgcnX","outputId":"10644168-2863-4760-d085-8c523076f240"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 9912422/9912422 [00:05<00:00, 1669801.10it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 28881/28881 [00:00<00:00, 2689155.39it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 2038217.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4542/4542 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["\n","data_loader = MNISTDataLoader()\n","train_data= data_loader.train_loader(50000)\n","test_data= data_loader.test_loader(10000)\n","\n","# print(len(train_data))\n","# print(len(test_data))"]},{"cell_type":"markdown","metadata":{"id":"It0H7em-gcnX"},"source":["(ب)تولید داده"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":446,"status":"ok","timestamp":1700336648112,"user":{"displayName":"Ahmad Karami","userId":"07297591222472337752"},"user_tz":-210},"id":"2m9Ee_0RgcnY"},"outputs":[],"source":["# make a random number that is not the excluded_number\n","def random_num(excluded_number):\n","    while True:\n","        number = torch.randint(low=0,high= 10, size=(1,)).item()\n","        if number != excluded_number:\n","            return number\n","\n","# genarate wrong label\n","def Wrong_labels(y):\n","    y_neg_i = []\n","    for _, y_i in enumerate(y):\n","        num = random_num(y_i)\n","        y_neg_i.append(num)\n","    y_neg = torch.tensor(y_neg_i, device=device)\n","    return y_neg\n","\n","# add y to the first 10 pixcel of each image\n","def combine_x_y(x, y, classes=10):\n","    x_new = x.clone()\n","    # add one hot vector to the first of each image\n","    x_new[:, :classes] *= 0.0\n","    x_new[range(x.shape[0]), y] = x.max()\n","    return x_new\n","\n"]},{"cell_type":"markdown","metadata":{"id":"uHVBObgfgcnZ"},"source":["(ج)پیاده سازی شبکه"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def Goodness(g_pos , g_neg , threshold):\n","    g_pos = g_pos.pow(2).mean(1)\n","    g_neg = g_neg.pow(2).mean(1)\n","    loss = torch.log1p( torch.exp(torch.cat([-g_pos + threshold, g_neg - threshold]))).mean()\n","    return loss"]},{"cell_type":"markdown","metadata":{},"source":["استفاده از این تعریف برای تابع لاس به این دلیل مناسب است که کاهش لاس به معنی افزایش تعداد خروجی درست در خروجی لایه و کاهش تعداد داده غلط است. جمع کردن عبارت داخل لوگاریتم با 1 باری جلوگیری از صفر شدن عبارت داخل لوگاریتمو, که لاس بینهایت ندهد."]},{"cell_type":"markdown","metadata":{},"source":["define Layer and Net class with help of this Github example from pytorch:\n","https://github.com/pytorch/examples/blob/main/mnist_forward_forward/main.py"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1700336648112,"user":{"displayName":"Ahmad Karami","userId":"07297591222472337752"},"user_tz":-210},"id":"7IRQBa45gcnZ"},"outputs":[],"source":["class Layer(nn.Linear):\n","    def __init__(self, in_features, out_features, lr=0.03 , threshold = 2.0 ,num_epochs = 1000,\n","                 bias=True, device=None, dtype=None):\n","        super().__init__(in_features, out_features, bias, device, dtype)\n","        self.relu = torch.nn.ReLU()\n","        self.opt = Adam(self.parameters(), lr = lr)\n","        self.threshold = threshold\n","        self.num_epochs = num_epochs\n","    # define a forward function that pass the input through a linrea relu function\n","    def forward(self, x):\n","        x_direction = x / (x.norm(2, 1, keepdim=True) + 1e-4)\n","        Linear_relu_out = self.relu(torch.mm(x_direction, self.weight.T) + self.bias.unsqueeze(0))\n","        return Linear_relu_out\n","    # define a function train to minimize the loos function with adam optimizer\n","    def train(self, x_pos, x_neg):\n","        for i in tqdm(range(self.num_epochs)):\n","            # compute the mean squared output of the model for\n","            # positive samples (x_pos) and negative samples (x_neg)\n","            g_pos = self.forward(x_pos)\n","            g_neg = self.forward(x_neg)\n","            # This loss pushes pos (neg) samples to\n","            # values larger (smaller) than the self.threshold\n","            loss = Goodness(g_pos , g_neg , self.threshold)\n","\n","            # clear the gradients of all optimized torch.Tensors\n","            self.opt.zero_grad()\n","            # gradients of the loss with respect to the model parameters\n","            loss.backward()\n","            #  update the parameters of the model based on the gradients\n","            self.opt.step()\n","            # detach() function is used to prevent further computation of gradients\n","            next_x_pos = self.forward(x_pos).detach()\n","            next_x_neg = self.forward(x_neg).detach()\n","\n","        return next_x_pos, next_x_neg\n"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1700336648112,"user":{"displayName":"Ahmad Karami","userId":"07297591222472337752"},"user_tz":-210},"id":"j20ajHwFgcna"},"outputs":[],"source":["class Net():\n","    def __init__(self, dims):\n","        self.layers = []\n","        for indx in range(len(dims) - 1):\n","            self.layers += [Layer(dims[indx ], dims[indx + 1]).cuda()]\n","    # get a image as input and give the greatest goodness\n","    def predict(self, x):\n","        goodness_per_label = []\n","        for label in range(10):\n","            h = combine_x_y(x, label)\n","            goodness = []\n","            for layer in self.layers:\n","                h = layer(h)\n","                goodness += [h.pow(2).mean(1)]\n","            goodness_per_label += [sum(goodness).unsqueeze(1)]\n","        goodness_per_label = torch.cat(goodness_per_label, 1)\n","        return goodness_per_label.argmax(1)\n","\n","    def train(self, x_pos, x_neg):\n","        h_pos, h_neg = x_pos, x_neg\n","        for i, layer in enumerate(self.layers):\n","            print('training layer', i, '...')\n","            \n","            h_pos, h_neg = layer.train(h_pos, h_neg)"]},{"cell_type":"markdown","metadata":{"id":"zO6OcULegcna"},"source":["(د)گزارش نتایج"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":202440,"status":"ok","timestamp":1700336850547,"user":{"displayName":"Ahmad Karami","userId":"07297591222472337752"},"user_tz":-210},"id":"tAjxSfn89baY","outputId":"111f3605-3dbd-487f-d603-3274447eb95b"},"outputs":[{"name":"stdout","output_type":"stream","text":["training layer 0 ...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [01:00<00:00, 16.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["training layer 1 ...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [00:42<00:00, 23.29it/s]\n"]},{"name":"stdout","output_type":"stream","text":["training layer 0 ...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [00:13<00:00, 73.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["training layer 1 ...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [00:09<00:00, 109.64it/s]\n"]}],"source":["torch.manual_seed(22)\n","net = Net([784, 500, 500])\n","x_train = iter(train_data)\n","# go through all the data and train the model\n","for x_data in x_train:\n","    x_t , y_t = x_data\n","    x_t , y_t = x_t.to(device) , y_t.to(device)\n","    # build the data with labels inside\n","    x_pos = combine_x_y(x_t, y_t)\n","    y_neg = Wrong_labels(y_t)\n","    x_neg = combine_x_y(x_t, y_neg)\n","    # train the network\n","    net.train(x_pos, x_neg)"]},{"cell_type":"markdown","metadata":{},"source":["accuracy:"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13371,"status":"ok","timestamp":1700336863914,"user":{"displayName":"Ahmad Karami","userId":"07297591222472337752"},"user_tz":-210},"id":"LLWWQwp69baZ","outputId":"84f02346-bf58-4517-b56f-2ea2b536960f"},"outputs":[{"name":"stdout","output_type":"stream","text":["train accuracy: 0.928266704082489\n"]}],"source":["x_train = iter(train_data)\n","First = True\n","for x_data in x_train:\n","    x_t , y_t = x_data\n","    x_t , y_t = x_t.to(device) , y_t.to(device)\n","    if First:\n","        accuracy = (net.predict(x_t) == y_t)\n","        First = False\n","    else:\n","        accuracy = torch.cat((accuracy , (net.predict(x_t) == y_t)), dim=0)\n","\n","accuracy = accuracy.float().mean().item()\n","print('train accuracy:',accuracy)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2355,"status":"ok","timestamp":1700336866266,"user":{"displayName":"Ahmad Karami","userId":"07297591222472337752"},"user_tz":-210},"id":"dP4ty5Po9baZ","outputId":"d679f193-0204-45ac-d60f-8e54c81cecd2"},"outputs":[{"name":"stdout","output_type":"stream","text":["test accuracy: 0.9298999905586243\n"]}],"source":["\n","x_test = iter(test_data)\n","First = True\n","for x_data in x_test:\n","    x_t , y_t = x_data\n","    x_t , y_t = x_t.to(device) , y_t.to(device)\n","    if First:\n","        accuracy = (net.predict(x_t) == y_t)\n","        First = False\n","    else:\n","        accuracy = torch.cat((accuracy , (net.predict(x_t) == y_t)), dim=0)\n","\n","accuracy = accuracy.float().mean().item()\n","print('test accuracy:',accuracy)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
